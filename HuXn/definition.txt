An algorithm is a set of instructions that tells a computer how to do something, or a step by step solution of a problem


Big O
o(n) -> linear time, algorithm grows as the input grows
o(1) -> algorithm takes constant time irrespective of the input size
o(n^2) -> grows quadratically as the input grows